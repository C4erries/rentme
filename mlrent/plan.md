## План развития ML‑сервиса Rentme

Цель: привести ML‑сервис (`mlrent/`) в соответствие с доменной моделью (Listing, Pricing), разделить модели для краткосрочной и долгосрочной аренды и встроить сервис в общий `docker-compose`.

---

### 1. Синхронизировать признаки CSV с доменом

- Зафиксировать схему `clean_train.csv` / `clean_test.csv`:
  - `id,city,price,minutes,way,rooms,total_area,storey,storeys,renovation,building_age_years`.
- Подтвердить маппинг на `Listing`:
  - `Address.City`, `Bedrooms`, `AreaSquareMeters`, `Floor`, `FloorsTotal`, `RenovationScore`, `BuildingAgeYears`.
- Описать в `mlrent/problem.md` и `domain_model.md`, какие признаки берутся напрямую из `Listing`, а какие (`minutes`, `way`) являются производными и задаются адаптером.

---

### 2. Обновить код модели под актуальную схему

- В `mlrent/ml.py`:
  - реализовать функцию парсинга CSV, которая:
    - читает текущую схему файлов;
    - кодирует `way` (`walk`/`car`) в числовой формат;
    - возвращает `data, labels` в подходящем для sklearn виде.
  - сохранить структуру файла (функции `build_model`, `train_from_csv`, `predict`), дополнив только необходимыми изменениями.

---

### 3. Добавить две модели: short_term и long_term

- В `mlrent/ml.py`:
  - добавить две обучающие обёртки: `train_short_term` и `train_long_term`;
  - завести отдельные CSV‑наборы для каждого типа аренды:
    - `clean_train_short.csv` / `clean_test_short.csv`;
    - `clean_train_long.csv` / `clean_test_long.csv`;
  - для каждого типа обеспечить разбиение данных **≈90% / 10%** (train/test);
  - для долгосрочной аренды опираться на уже существующий датасет (текущие `clean_train`/`clean_test`), для посуточной — сгенерировать новый датасет с похожими распределениями признаков;
  - хранить/подгружать два экземпляра модели: `short_term_model` и `long_term_model`.
- В `mlrent/main.py`:
  - на старте обучать/загружать обе модели;
  - расширить схему запроса полем `rental_term` (`"short_term" | "long_term"`) либо добавить отдельные endpoint’ы (`/predict/short`, `/predict/long`).

---

### 4. Уточнить HTTP‑контракт для backend‑адаптера

- В `mlrent/readme.md` чётко описать:
  - обязательные поля запроса:
    - `city`, `rooms`, `total_area`, `storey`, `storeys`, `renovation`, `building_age_years`, `rental_term`;
  - дополнительные/опциональные поля:
    - `minutes`, `way`, `current_price`;
  - формат ответа:
    - `recommended_price`, опционально `current_price`, `diff`.
- Обеспечить обратную совместимость:
  - по возможности не ломать текущий `/predict`;
  - при необходимости добавить новые endpoint’ы для short/long, оставив старый в режиме совместимости.

---

### 5. Подготовить Docker‑образ и интеграцию в compose

- Упростить `mlrent/Dockerfile` до минимального образа (Python + необходимые зависимости).
- Обновить корневой `docker-compose.yml`:
  - добавить сервис `rentme-ml` c портом (например, `8000`);
  - подключить его к сети backend;
  - передавать URL через переменную `ML_PRICING_URL`.
- Проверить, что при `PRICING_MODE=ml` backend обращается к ML‑сервису и корректно мапит результат в `PriceBreakdown`.

---

### 6. Метрики качества и отладка

- В `mlrent/ml.py` реализовать оценку качества на тестовых наборах:
  - минимум MAE/MAPE для `short_term` и `long_term` отдельно.
- Сделать метрики доступными:
  - либо через логирование при старте в понятном формате;
  - либо через endpoint (например, `GET /metrics`), возвращающий значения по сегментам.
- Описать формат метрик и способ получения в `mlrent/readme.md`, чтобы админка могла их отображать.

---

### 7. Генерация данных и заполнение базы

- Подготовить скрипт/утилиту (Python или Go) для генерации демонстрационных данных:
  - не менее ~30 объявлений `short_term` и ~30 объявлений `long_term`;
  - несколько разных арендодателей: пара «агентств» и пара частных лиц.
- Сгенерированные объявления должны по параметрам (город, комнаты, площадь, этаж/этажность, ремонт, возраст дома, тип аренды) быть **похожи на строки в CSV‑датасетах**.
- Скрипт должен:
  - создавать пользователей‑арендодателей и объявления в Mongo;
  - при необходимости генерировать/обновлять CSV‑файлы для посуточной выборки, чтобы данные для обучения и для заполнения базы были согласованы.

